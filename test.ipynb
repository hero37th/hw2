{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "import glob\n",
    "import math\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import models\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "train_root = \"/home/yulin/Documents/DLCV/hw2/hw2_train_val/train15000/\"\n",
    "test_root = \"/home/yulin/Documents/DLCV/hw2/hw2_train_val/val1500/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used: cpu\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available, otherwise stick with cpu\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(123)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print('Device used:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MYDATASET(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        \"\"\" Intialize the MNIST dataset \"\"\"\n",
    "        self.images = None\n",
    "        self.labels = None\n",
    "        self.filenames = []\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        #     parent = os.path.join(path, i)　　read filenames\n",
    "        path = root+\"images/\"\n",
    "        path_ = root+\"labelTxt_hbb/\"\n",
    "        self.filenames=sorted(glob.glob(os.path.join(path,'*.jpg')))\n",
    "        self.txtnames=sorted(glob.glob(os.path.join(path_,'*.txt')))\n",
    "        self.len = len(self.filenames)\n",
    "                              \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Get a sample from the dataset \"\"\"\n",
    "        image_fn = self.filenames[index]\n",
    "        temp = Image.open(image_fn).convert('RGB')\n",
    "        image = temp.resize((448, 448),Image.ANTIALIAS)    \n",
    "        f = open(self.txtnames[index])\n",
    "        line = f.readline()\n",
    "        list = []\n",
    "        while line:\n",
    "            a = line.split( )\n",
    "            b = a[0:]\n",
    "            list.append(b)\n",
    "            line = f.readline()\n",
    "        f.close\n",
    "        label_one=np.zeros((7,7,26))\n",
    "        for s in range(len(list)):\n",
    "            x=0.5*(float(list[s][2])+float(list[s][0]))/512\n",
    "            y=0.5*(float(list[s][5])+float(list[s][1]))/512\n",
    "            w=1*(float(list[s][2])-float(list[s][0]))/512\n",
    "            h=1*(float(list[s][5])-float(list[s][1]))/512\n",
    "            class_=list[s][8]\n",
    "            diff_=list[s][9]\n",
    "            i=math.floor(7*x)\n",
    "            j=math.floor(7*y)\n",
    "            if label_one[i][j][0]==0:\n",
    "                \n",
    "                label_one[i][j][0]=x\n",
    "                label_one[i][j][1]=y\n",
    "                label_one[i][j][2]=w\n",
    "                label_one[i][j][3]=h\n",
    "                label_one[i][j][4]=1\n",
    "                if class_==str('plane'):\n",
    "                    label_one[i][j][10]=1\n",
    "                if class_==str('ship'):\n",
    "                    label_one[i][j][11]=1\n",
    "                if class_==str('storage-tank'):\n",
    "                    label_one[i][j][12]=1\n",
    "                if class_==str('baseball-diamond'):\n",
    "                    label_one[i][j][13]=1\n",
    "                if class_==str('tennis-court'):\n",
    "                    label_one[i][j][14]=1\n",
    "                if class_==str('basketball-court'):\n",
    "                    label_one[i][j][15]=1\n",
    "                if class_==str('ground-track-field'):\n",
    "                    label_one[i][j][16]=1\n",
    "                if class_==str('harbor'):\n",
    "                    label_one[i][j][17]=1\n",
    "                if class_==str('bridge'):\n",
    "                    label_one[i][j][18]=1\n",
    "                if class_==str('small-vehicle'):\n",
    "                    label_one[i][j][19]=1\n",
    "                if class_==str('large-vehicle'):\n",
    "                    label_one[i][j][20]=1\n",
    "                if class_==str('helicopter'):\n",
    "                    label_one[i][j][21]=1\n",
    "                if class_==str('roundabout'):\n",
    "                    label_one[i][j][22]=1\n",
    "                if class_==str('soccer-ball-field'):\n",
    "                    label_one[i][j][23]=1\n",
    "                if class_==str('swimming-pool'):\n",
    "                    label_one[i][j][24]=1\n",
    "                if class_==str('container-crane'):\n",
    "                    label_one[i][j][25]=1\n",
    "            else:\n",
    "                pass\n",
    "            label = torch.from_numpy(label_one).type(torch.float)\n",
    "            \n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" Total number of samples in the dataset \"\"\"\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset=MYDATASET(root=train_root, transform=transforms.ToTensor())\n",
    "testset=MYDATASET(root=test_root, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('# images in trainset:', len(trainset)) # Should print 15000\n",
    "#print('# images in testset:', len(testset)) # Should print 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image tensor in each batch: torch.Size([5, 3, 448, 448]) torch.float32\n",
      "Label tensor in each batch: torch.Size([5, 7, 7, 26]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "trainset_loader = DataLoader(trainset, batch_size=5, shuffle=True, num_workers=1)\n",
    "testset_loader = DataLoader(testset, batch_size=5, shuffle=False, num_workers=1)\n",
    "# get some random training images\n",
    "dataiter = iter(trainset_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print('Image tensor in each batch:', images.shape, images.dtype)\n",
    "print('Label tensor in each batch:', labels.shape, labels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge(inputs):\n",
    "    a=torch.unbind(inputs, dim=3)[1]\n",
    "    index=torch.nonzero(a)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Yolov1_vgg16bn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 7, 7, 26])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssd=model(images)\n",
    "ssd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=judge(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0284, 0.0000, 0.0000, 0.1473, 0.0000, 0.0000, 0.0000, 0.0000, 0.0079,\n",
      "        0.1434], grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "index=judge(labels)\n",
    "def iou(inputs, targets, index, e):\n",
    "    score=torch.zeros(len(index))\n",
    "    a=0\n",
    "    for k,i,j in index:\n",
    "        squ_label=targets[k][i][j][0:4]\n",
    "        squ_model=inputs[k][i][j][0+e:4+e]\n",
    "        x_min1=squ_label[0]-0.5*squ_label[2]\n",
    "        x_max1=squ_label[0]+0.5*squ_label[2]\n",
    "        y_min1=squ_label[1]-0.5*squ_label[3]\n",
    "        y_max1=squ_label[1]+0.5*squ_label[3]\n",
    "        x_min2=squ_model[0]-0.5*squ_model[2]\n",
    "        x_max2=squ_model[0]+0.5*squ_model[2]\n",
    "        y_min2=squ_model[1]-0.5*squ_model[3]  \n",
    "        y_max2=squ_model[1]+0.5*squ_model[3]\n",
    "\n",
    "        ww=torch.min(x_max1,x_max2)-torch.max(x_min1,x_min2)\n",
    "        hh=torch.min(y_max1,y_max2)-torch.max(x_min1,y_min2)\n",
    "        b1_area=(x_max1-x_min1) *(y_max1-y_min1)\n",
    "        b2_area=(x_max2-x_min2) *(y_max2-y_min2)\n",
    "\n",
    "        if ww<=0 or hh<=0:\n",
    "            a=a+1\n",
    "        else:\n",
    "            score[a] = (ww*hh) / (b1_area + b2_area - ww*hh + 1e-16)\n",
    "            a=a+1\n",
    "\n",
    "    return score\n",
    "score=iou(ssd,labels,index,1)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossFunc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LossFunc, self).__init__()   \n",
    "        #number\n",
    "        s=7\n",
    "        ss=s*s\n",
    "        coord=5\n",
    "        noodj=0.5    \n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        s=7\n",
    "        ss=s*s\n",
    "        coord=5\n",
    "        noodj=0.5\n",
    "        num=torch.numel(inputs[:, 0, 0, 0]) \n",
    "        index=judge(targets)\n",
    "        delta_sum=0\n",
    "        for k,i,j in index:\n",
    "            temp=inputs[k, i, j, 1:3]-targets[k, i, j, 1:3]\n",
    "            delta_xy1=torch.sum(torch.pow(temp,2))\n",
    "            temp2=torch.sqrt(inputs[k, i, j, 3:5])-torch.sqrt(labels[k, i, j, 3:5])\n",
    "            delta_wh1=torch.sum(torch.pow(temp2,2))\n",
    "            temp3=inputs[k, i, j, 6:8]-targets[k, i, j, 1:3]\n",
    "            delta_xy2=torch.sum(torch.pow(temp3,2))\n",
    "            temp4=torch.sqrt(inputs[k, i, j, 8:10])-torch.sqrt(labels[k, i, j, 3:5])\n",
    "            delta_wh2=torch.sum(torch.pow(temp4,2))\n",
    "            delta_sum = delta_sum+delta_wh1+delta_xy1+delta_wh2+delta_xy2\n",
    "        first=coord*delta_sum/num#中心點誤差\n",
    "        \n",
    "        confidence1=iou(inputs, targets, index,0)#獲得1置信度與概率\n",
    "        confidence2=iou(inputs, targets, index,1)#獲得2置信度與概率\n",
    "        pr=torch.le(confidence1, confidence2) \n",
    "        hat_c=torch.FloatTensor(len(confidence1),2).zero_()\n",
    "        n1=torch.FloatTensor(len(confidence1)).zero_()\n",
    "        n2=torch.FloatTensor(len(confidence1)).zero_()\n",
    "        m1=torch.FloatTensor(len(confidence1)).zero_()\n",
    "        m=0\n",
    "        second=0\n",
    "        for k,i,j in index:\n",
    "                    hat_c[m][0]=inputs[k, i, j, 4:5]\n",
    "                    hat_c[m][1]=inputs[k, i, j, 9:10]\n",
    "                    m=m+1\n",
    "        for t in range(len(confidence1)):\n",
    "            if pr[t]==0:\n",
    "                n1[t] = hat_c[t][0]\n",
    "                n2[t] = hat_c[t][1]\n",
    "                m1[t] = confidence1[t]\n",
    "            else:\n",
    "                n2[t] = hat_c[t][0]\n",
    "                n1[t] = hat_c[t][1]\n",
    "                m1[t] = confidence２[t]\n",
    "\n",
    "        tar_1=torch.pow(n1-m1,2)\n",
    "        tar_2=torch.pow(n2,2)\n",
    "        second=torch.sum(tar_1+noodj*tar_2)\n",
    "\n",
    "        third=0    \n",
    "        for k,i,j in index:\n",
    "            obj=torch.squeeze(targets[k, i, j, 10:])\n",
    "            sss=torch.squeeze(inputs[k, i, j, 10:])\n",
    "            e=torch.pow((obj-sss),2)\n",
    "            third=third+torch.sum(e)\n",
    "            \n",
    "            \n",
    "        loss=(first+second+third)/num\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0263, grad_fn=<DivBackward0>)\n",
      "tensor(0., grad_fn=<MulBackward0>)\n",
      "tensor(0., grad_fn=<DivBackward0>)\n",
      "tensor(0.0759, grad_fn=<DivBackward0>)\n",
      "tensor(0.0785, grad_fn=<DivBackward0>)\n",
      "tensor(0.0223, grad_fn=<DivBackward0>)\n",
      "tensor(0., grad_fn=<DivBackward0>)\n",
      "tensor(0., grad_fn=<MulBackward0>)\n",
      "tensor(0.0021, grad_fn=<DivBackward0>)\n",
      "tensor(0.2134, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def iou2(box1,box2):\n",
    "\n",
    "    x_min1=box1[0]-0.5*box1[2]\n",
    "    x_max1=box1[0]+0.5*box1[2]\n",
    "    y_min1=box1[1]-0.5*box1[3]\n",
    "    y_max1=box1[1]+0.5*box1[3]\n",
    "    x_min2=box2[0]-0.5*box2[2]\n",
    "    x_max2=box2[0]+0.5*box2[2]\n",
    "    y_min2=box2[1]-0.5*box2[3]  \n",
    "    y_max2=box2[1]+0.5*box2[3]\n",
    "    ww=torch.min(x_max1,x_max2)-torch.max(x_min1,x_min2)\n",
    "    hh=torch.min(y_max1,y_max2)-torch.max(y_min1,y_min2)\n",
    "    b1_area=(x_max1-x_min1) *(y_max1-y_min1)\n",
    "    b2_area=(x_max2-x_min2) *(y_max2-y_min2)\n",
    "\n",
    "    interArea= max(0, hh) * max(0, ww)\n",
    "    score = interArea / (b1_area + b2_area - ww*hh + 1e-16) \n",
    "    return score\n",
    "for k,i,j in index:\n",
    "    w=iou2(ssd[k][i][j][0:4],labels[k][i][j][0:4])\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, log_interval=100):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    criterion=LossFunc()\n",
    "    model.train()  # Important: set training mode\n",
    "    \n",
    "    iteration = 0\n",
    "    for ep in range(epoch):\n",
    "        for batch_idx, (data, target) in enumerate(trainset_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if iteration % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    ep, batch_idx * len(data), len(trainset_loader.dataset),\n",
    "                    100. * batch_idx / len(trainset_loader), loss.item()))\n",
    "            iteration += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/15000 (0%)]\tLoss: 17.902967\n",
      "Train Epoch: 0 [100/15000 (1%)]\tLoss: 7.778686\n",
      "Train Epoch: 0 [200/15000 (1%)]\tLoss: 1.230989\n",
      "Train Epoch: 0 [300/15000 (2%)]\tLoss: 10.256804\n",
      "Train Epoch: 0 [400/15000 (3%)]\tLoss: 1.027899\n",
      "Train Epoch: 0 [500/15000 (3%)]\tLoss: 1.809370\n",
      "Train Epoch: 0 [600/15000 (4%)]\tLoss: 3.654349\n",
      "Train Epoch: 0 [700/15000 (5%)]\tLoss: 1.495774\n",
      "Train Epoch: 0 [800/15000 (5%)]\tLoss: 6.316463\n",
      "Train Epoch: 0 [900/15000 (6%)]\tLoss: 5.378819\n",
      "Train Epoch: 0 [1000/15000 (7%)]\tLoss: 0.897084\n",
      "Train Epoch: 0 [1100/15000 (7%)]\tLoss: 3.616435\n",
      "Train Epoch: 0 [1200/15000 (8%)]\tLoss: 1.577830\n",
      "Train Epoch: 0 [1300/15000 (9%)]\tLoss: 4.858388\n",
      "Train Epoch: 0 [1400/15000 (9%)]\tLoss: 9.453559\n",
      "Train Epoch: 0 [1500/15000 (10%)]\tLoss: 41.105217\n",
      "Train Epoch: 0 [1600/15000 (11%)]\tLoss: 3.864344\n",
      "Train Epoch: 0 [1700/15000 (11%)]\tLoss: 0.752075\n",
      "Train Epoch: 0 [1800/15000 (12%)]\tLoss: 1.732554\n",
      "Train Epoch: 0 [1900/15000 (13%)]\tLoss: 33.614349\n",
      "Train Epoch: 0 [2000/15000 (13%)]\tLoss: 17.839891\n",
      "Train Epoch: 0 [2100/15000 (14%)]\tLoss: 1.282237\n",
      "Train Epoch: 0 [2200/15000 (15%)]\tLoss: 25.892857\n",
      "Train Epoch: 0 [2300/15000 (15%)]\tLoss: 2.704881\n",
      "Train Epoch: 0 [2400/15000 (16%)]\tLoss: 0.743191\n",
      "Train Epoch: 0 [2500/15000 (17%)]\tLoss: 6.964436\n",
      "Train Epoch: 0 [2600/15000 (17%)]\tLoss: 2.993775\n",
      "Train Epoch: 0 [2700/15000 (18%)]\tLoss: 4.716646\n",
      "Train Epoch: 0 [2800/15000 (19%)]\tLoss: 1.439778\n",
      "Train Epoch: 0 [2900/15000 (19%)]\tLoss: 2.671851\n",
      "Train Epoch: 0 [3000/15000 (20%)]\tLoss: 0.779332\n",
      "Train Epoch: 0 [3100/15000 (21%)]\tLoss: 1.222615\n",
      "Train Epoch: 0 [3200/15000 (21%)]\tLoss: 0.880629\n",
      "Train Epoch: 0 [3300/15000 (22%)]\tLoss: 0.737206\n",
      "Train Epoch: 0 [3400/15000 (23%)]\tLoss: 2.858900\n",
      "Train Epoch: 0 [3500/15000 (23%)]\tLoss: 2.304559\n",
      "Train Epoch: 0 [3600/15000 (24%)]\tLoss: 0.575637\n",
      "Train Epoch: 0 [3700/15000 (25%)]\tLoss: 2.948325\n",
      "Train Epoch: 0 [3800/15000 (25%)]\tLoss: 7.076296\n",
      "Train Epoch: 0 [3900/15000 (26%)]\tLoss: 11.149880\n",
      "Train Epoch: 0 [4000/15000 (27%)]\tLoss: 2.196876\n",
      "Train Epoch: 0 [4100/15000 (27%)]\tLoss: 8.727643\n",
      "Train Epoch: 0 [4200/15000 (28%)]\tLoss: 1.720611\n",
      "Train Epoch: 0 [4300/15000 (29%)]\tLoss: 16.571491\n",
      "Train Epoch: 0 [4400/15000 (29%)]\tLoss: 3.901698\n",
      "Train Epoch: 0 [4500/15000 (30%)]\tLoss: 4.043376\n",
      "Train Epoch: 0 [4600/15000 (31%)]\tLoss: 2.124195\n",
      "Train Epoch: 0 [4700/15000 (31%)]\tLoss: 1.084997\n",
      "Train Epoch: 0 [4800/15000 (32%)]\tLoss: 9.751211\n",
      "Train Epoch: 0 [4900/15000 (33%)]\tLoss: 0.833498\n",
      "Train Epoch: 0 [5000/15000 (33%)]\tLoss: 16.749134\n",
      "Train Epoch: 0 [5100/15000 (34%)]\tLoss: 1.244295\n",
      "Train Epoch: 0 [5200/15000 (35%)]\tLoss: 1.052011\n",
      "Train Epoch: 0 [5300/15000 (35%)]\tLoss: 0.624947\n",
      "Train Epoch: 0 [5400/15000 (36%)]\tLoss: 25.128727\n",
      "Train Epoch: 0 [5500/15000 (37%)]\tLoss: 0.698784\n",
      "Train Epoch: 0 [5600/15000 (37%)]\tLoss: 11.339544\n",
      "Train Epoch: 0 [5700/15000 (38%)]\tLoss: 0.659627\n",
      "Train Epoch: 0 [5800/15000 (39%)]\tLoss: 5.840654\n",
      "Train Epoch: 0 [5900/15000 (39%)]\tLoss: 33.434891\n",
      "Train Epoch: 0 [6000/15000 (40%)]\tLoss: 0.669973\n",
      "Train Epoch: 0 [6100/15000 (41%)]\tLoss: 4.993708\n",
      "Train Epoch: 0 [6200/15000 (41%)]\tLoss: 2.194511\n",
      "Train Epoch: 0 [6300/15000 (42%)]\tLoss: 2.221876\n",
      "Train Epoch: 0 [6400/15000 (43%)]\tLoss: 3.662655\n",
      "Train Epoch: 0 [6500/15000 (43%)]\tLoss: 0.587718\n",
      "Train Epoch: 0 [6600/15000 (44%)]\tLoss: 0.533796\n",
      "Train Epoch: 0 [6700/15000 (45%)]\tLoss: 2.744260\n",
      "Train Epoch: 0 [6800/15000 (45%)]\tLoss: 6.169703\n",
      "Train Epoch: 0 [6900/15000 (46%)]\tLoss: 1.849631\n",
      "Train Epoch: 0 [7000/15000 (47%)]\tLoss: 0.576771\n",
      "Train Epoch: 0 [7100/15000 (47%)]\tLoss: 7.828423\n",
      "Train Epoch: 0 [7200/15000 (48%)]\tLoss: 2.241011\n",
      "Train Epoch: 0 [7300/15000 (49%)]\tLoss: 18.262888\n",
      "Train Epoch: 0 [7400/15000 (49%)]\tLoss: 21.397038\n",
      "Train Epoch: 0 [7500/15000 (50%)]\tLoss: 1.187916\n",
      "Train Epoch: 0 [7600/15000 (51%)]\tLoss: 1.167211\n",
      "Train Epoch: 0 [7700/15000 (51%)]\tLoss: 0.693661\n",
      "Train Epoch: 0 [7800/15000 (52%)]\tLoss: 0.965553\n",
      "Train Epoch: 0 [7900/15000 (53%)]\tLoss: 2.313667\n",
      "Train Epoch: 0 [8000/15000 (53%)]\tLoss: 30.299313\n",
      "Train Epoch: 0 [8100/15000 (54%)]\tLoss: 7.301886\n",
      "Train Epoch: 0 [8200/15000 (55%)]\tLoss: 8.476575\n",
      "Train Epoch: 0 [8300/15000 (55%)]\tLoss: 16.716667\n",
      "Train Epoch: 0 [8400/15000 (56%)]\tLoss: 7.474303\n",
      "Train Epoch: 0 [8500/15000 (57%)]\tLoss: 12.506057\n",
      "Train Epoch: 0 [8600/15000 (57%)]\tLoss: 6.359006\n",
      "Train Epoch: 0 [8700/15000 (58%)]\tLoss: 1.379243\n",
      "Train Epoch: 0 [8800/15000 (59%)]\tLoss: 5.203684\n",
      "Train Epoch: 0 [8900/15000 (59%)]\tLoss: 2.055681\n",
      "Train Epoch: 0 [9000/15000 (60%)]\tLoss: 11.332213\n",
      "Train Epoch: 0 [9100/15000 (61%)]\tLoss: 10.636485\n",
      "Train Epoch: 0 [9200/15000 (61%)]\tLoss: 14.535738\n",
      "Train Epoch: 0 [9300/15000 (62%)]\tLoss: 1.582968\n",
      "Train Epoch: 0 [9400/15000 (63%)]\tLoss: 5.808685\n",
      "Train Epoch: 0 [9500/15000 (63%)]\tLoss: 1.536921\n",
      "Train Epoch: 0 [9600/15000 (64%)]\tLoss: 17.447466\n",
      "Train Epoch: 0 [9700/15000 (65%)]\tLoss: 8.240196\n",
      "Train Epoch: 0 [9800/15000 (65%)]\tLoss: 2.517070\n",
      "Train Epoch: 0 [9900/15000 (66%)]\tLoss: 4.521092\n",
      "Train Epoch: 0 [10000/15000 (67%)]\tLoss: 8.817352\n",
      "Train Epoch: 0 [10100/15000 (67%)]\tLoss: 11.883516\n",
      "Train Epoch: 0 [10200/15000 (68%)]\tLoss: 1.020247\n",
      "Train Epoch: 0 [10300/15000 (69%)]\tLoss: 13.228718\n",
      "Train Epoch: 0 [10400/15000 (69%)]\tLoss: 9.467560\n",
      "Train Epoch: 0 [10500/15000 (70%)]\tLoss: 18.498495\n",
      "Train Epoch: 0 [10600/15000 (71%)]\tLoss: 1.108001\n",
      "Train Epoch: 0 [10700/15000 (71%)]\tLoss: 7.805051\n",
      "Train Epoch: 0 [10800/15000 (72%)]\tLoss: 1.881801\n",
      "Train Epoch: 0 [10900/15000 (73%)]\tLoss: 29.354006\n",
      "Train Epoch: 0 [11000/15000 (73%)]\tLoss: 6.387918\n",
      "Train Epoch: 0 [11100/15000 (74%)]\tLoss: 3.940523\n",
      "Train Epoch: 0 [11200/15000 (75%)]\tLoss: 6.154950\n",
      "Train Epoch: 0 [11300/15000 (75%)]\tLoss: 10.147156\n",
      "Train Epoch: 0 [11400/15000 (76%)]\tLoss: 6.153563\n",
      "Train Epoch: 0 [11500/15000 (77%)]\tLoss: 0.590609\n",
      "Train Epoch: 0 [11600/15000 (77%)]\tLoss: 18.407608\n",
      "Train Epoch: 0 [11700/15000 (78%)]\tLoss: 0.529035\n",
      "Train Epoch: 0 [11800/15000 (79%)]\tLoss: 0.866895\n",
      "Train Epoch: 0 [11900/15000 (79%)]\tLoss: 19.122534\n",
      "Train Epoch: 0 [12000/15000 (80%)]\tLoss: 9.368995\n",
      "Train Epoch: 0 [12100/15000 (81%)]\tLoss: 4.200062\n",
      "Train Epoch: 0 [12200/15000 (81%)]\tLoss: 5.402841\n",
      "Train Epoch: 0 [12300/15000 (82%)]\tLoss: 0.612128\n",
      "Train Epoch: 0 [12400/15000 (83%)]\tLoss: 0.588740\n",
      "Train Epoch: 0 [12500/15000 (83%)]\tLoss: 5.386811\n",
      "Train Epoch: 0 [12600/15000 (84%)]\tLoss: 3.613887\n",
      "Train Epoch: 0 [12700/15000 (85%)]\tLoss: 1.438884\n",
      "Train Epoch: 0 [12800/15000 (85%)]\tLoss: 0.485886\n",
      "Train Epoch: 0 [12900/15000 (86%)]\tLoss: 0.486168\n",
      "Train Epoch: 0 [13000/15000 (87%)]\tLoss: 9.793468\n",
      "Train Epoch: 0 [13100/15000 (87%)]\tLoss: 8.936161\n",
      "Train Epoch: 0 [13200/15000 (88%)]\tLoss: 2.350319\n",
      "Train Epoch: 0 [13300/15000 (89%)]\tLoss: 17.666935\n",
      "Train Epoch: 0 [13400/15000 (89%)]\tLoss: 2.947506\n",
      "Train Epoch: 0 [13500/15000 (90%)]\tLoss: 13.080320\n",
      "Train Epoch: 0 [13600/15000 (91%)]\tLoss: 14.259966\n",
      "Train Epoch: 0 [13700/15000 (91%)]\tLoss: 5.410775\n",
      "Train Epoch: 0 [13800/15000 (92%)]\tLoss: 0.728387\n",
      "Train Epoch: 0 [13900/15000 (93%)]\tLoss: 1.462842\n",
      "Train Epoch: 0 [14000/15000 (93%)]\tLoss: 9.399252\n",
      "Train Epoch: 0 [14100/15000 (94%)]\tLoss: 0.500830\n",
      "Train Epoch: 0 [14200/15000 (95%)]\tLoss: 4.197966\n",
      "Train Epoch: 0 [14300/15000 (95%)]\tLoss: 0.624472\n",
      "Train Epoch: 0 [14400/15000 (96%)]\tLoss: 23.665634\n",
      "Train Epoch: 0 [14500/15000 (97%)]\tLoss: 10.197883\n",
      "Train Epoch: 0 [14600/15000 (97%)]\tLoss: 7.154216\n",
      "Train Epoch: 0 [14700/15000 (98%)]\tLoss: 29.483536\n",
      "Train Epoch: 0 [14800/15000 (99%)]\tLoss: 2.015193\n",
      "Train Epoch: 0 [14900/15000 (99%)]\tLoss: 14.775534\n",
      "Train Epoch: 1 [0/15000 (0%)]\tLoss: 20.275780\n",
      "Train Epoch: 1 [100/15000 (1%)]\tLoss: 5.899431\n",
      "Train Epoch: 1 [200/15000 (1%)]\tLoss: 3.106943\n",
      "Train Epoch: 1 [300/15000 (2%)]\tLoss: 5.353647\n",
      "Train Epoch: 1 [400/15000 (3%)]\tLoss: 2.182467\n",
      "Train Epoch: 1 [500/15000 (3%)]\tLoss: 20.914957\n",
      "Train Epoch: 1 [600/15000 (4%)]\tLoss: 1.015181\n",
      "Train Epoch: 1 [700/15000 (5%)]\tLoss: 1.222319\n",
      "Train Epoch: 1 [800/15000 (5%)]\tLoss: 0.938126\n",
      "Train Epoch: 1 [900/15000 (6%)]\tLoss: 6.671920\n",
      "Train Epoch: 1 [1000/15000 (7%)]\tLoss: 1.040696\n",
      "Train Epoch: 1 [1100/15000 (7%)]\tLoss: 31.639183\n",
      "Train Epoch: 1 [1200/15000 (8%)]\tLoss: 5.299803\n",
      "Train Epoch: 1 [1300/15000 (9%)]\tLoss: 0.729438\n",
      "Train Epoch: 1 [1400/15000 (9%)]\tLoss: 11.593202\n",
      "Train Epoch: 1 [1500/15000 (10%)]\tLoss: 16.187189\n",
      "Train Epoch: 1 [1600/15000 (11%)]\tLoss: 8.583621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1700/15000 (11%)]\tLoss: 2.843520\n",
      "Train Epoch: 1 [1800/15000 (12%)]\tLoss: 11.217308\n",
      "Train Epoch: 1 [1900/15000 (13%)]\tLoss: 0.491225\n",
      "Train Epoch: 1 [2000/15000 (13%)]\tLoss: 0.685102\n",
      "Train Epoch: 1 [2100/15000 (14%)]\tLoss: 5.427510\n",
      "Train Epoch: 1 [2200/15000 (15%)]\tLoss: 16.527828\n",
      "Train Epoch: 1 [2300/15000 (15%)]\tLoss: 10.634339\n",
      "Train Epoch: 1 [2400/15000 (16%)]\tLoss: 3.207422\n",
      "Train Epoch: 1 [2500/15000 (17%)]\tLoss: 4.747562\n",
      "Train Epoch: 1 [2600/15000 (17%)]\tLoss: 1.056015\n",
      "Train Epoch: 1 [2700/15000 (18%)]\tLoss: 3.316047\n",
      "Train Epoch: 1 [2800/15000 (19%)]\tLoss: 13.803205\n",
      "Train Epoch: 1 [2900/15000 (19%)]\tLoss: 18.562969\n",
      "Train Epoch: 1 [3000/15000 (20%)]\tLoss: 12.270779\n",
      "Train Epoch: 1 [3100/15000 (21%)]\tLoss: 16.378767\n",
      "Train Epoch: 1 [3200/15000 (21%)]\tLoss: 0.488505\n",
      "Train Epoch: 1 [3300/15000 (22%)]\tLoss: 0.528304\n",
      "Train Epoch: 1 [3400/15000 (23%)]\tLoss: 6.785482\n",
      "Train Epoch: 1 [3500/15000 (23%)]\tLoss: 7.996471\n",
      "Train Epoch: 1 [3600/15000 (24%)]\tLoss: 0.752838\n",
      "Train Epoch: 1 [3700/15000 (25%)]\tLoss: 4.883144\n",
      "Train Epoch: 1 [3800/15000 (25%)]\tLoss: 10.601529\n",
      "Train Epoch: 1 [3900/15000 (26%)]\tLoss: 20.339033\n",
      "Train Epoch: 1 [4000/15000 (27%)]\tLoss: 8.943215\n",
      "Train Epoch: 1 [4100/15000 (27%)]\tLoss: 9.908837\n",
      "Train Epoch: 1 [4200/15000 (28%)]\tLoss: 9.569477\n",
      "Train Epoch: 1 [4300/15000 (29%)]\tLoss: 0.655336\n",
      "Train Epoch: 1 [4400/15000 (29%)]\tLoss: 1.147860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/yulin/anaconda3/envs/dlcv/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/yulin/anaconda3/envs/dlcv/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/yulin/anaconda3/envs/dlcv/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/yulin/anaconda3/envs/dlcv/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-6fdf34e74563>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-4891dfcfbf7f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, epoch, log_interval)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;31m#data, target = data.to(device), target.to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlcv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/DLCV/hw2/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myolo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlcv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlcv/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlcv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlcv/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 320\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=ssd\n",
    "def get_score(inputs):\n",
    "    tem=inputs[:,0,0,0]\n",
    "    #for p in range(torch.numel(tem)):\n",
    "    boxobject,ind=torch.max(inputs[:,:,:,10:],3)#max class score\n",
    "    point2=inputs[:,:,:,9]\n",
    "    point1=inputs[:,:,:,4]\n",
    "    m = nn.Threshold(0.1, 0)\n",
    "    k=torch.cat((point2,point1) ,1)\n",
    "    t=torch.cat((boxobject,boxobject) ,1)\n",
    "    u=torch.cat((ind,ind) ,1)\n",
    "    kt=m(k*t) #置信度分數\n",
    "\n",
    "    get_index=torch.LongTensor()\n",
    "    lists=torch.LongTensor()\n",
    "    score=torch.ones(kt.size())\n",
    "\n",
    "    while torch.max(score) != 0:\n",
    "\n",
    "        for p in range(torch.numel(tem)):\n",
    "\n",
    "            s=torch.argmax(kt[p,:])\n",
    "            d=torch.max(kt[p,:])\n",
    "            y=s%7;\n",
    "            x=((s-y)/7)%7\n",
    "            z=ind[p][x%7][y]\n",
    "            k=x/7\n",
    "\n",
    "            kt[p,x,y]=0\n",
    "\n",
    "            lists=torch.cat((torch.tensor([p]),x.view(1),y.view(1),z.view(1)),0).view(1,-1)\n",
    "            get_index=torch.cat((get_index,lists),0)\n",
    "\n",
    "            for p in range(torch.numel(tem)):\n",
    "                for i in range(7):\n",
    "                    for j in range(7):\n",
    "                        for u in range(2):\n",
    "                            box1=inputs[p,i,j,0+u:4+u]\n",
    "                            box2=inputs[p,x,y,0+k:4+k]\n",
    "                            iou = iou2(box1,box2)\n",
    "                            if iou > 0.5:\n",
    "                                score[p][i+u*7][j]=0\n",
    "                            else:\n",
    "                                pass\n",
    "\n",
    "    return get_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  1,  0],\n",
       "        [ 1,  3,  0, 15],\n",
       "        [ 2,  6,  6,  3],\n",
       "        [ 3,  6,  0, 10],\n",
       "        [ 4,  2,  5,  2],\n",
       "        [ 0,  5,  6, 11],\n",
       "        [ 1,  3,  0, 15],\n",
       "        [ 2,  1,  4,  8],\n",
       "        [ 3,  2,  3,  1],\n",
       "        [ 4,  2,  5,  2],\n",
       "        [ 0,  5,  6, 11],\n",
       "        [ 1,  3,  0, 15],\n",
       "        [ 2,  2,  3,  1],\n",
       "        [ 3,  2,  3,  1],\n",
       "        [ 4,  2,  5,  2],\n",
       "        [ 0,  5,  6, 11],\n",
       "        [ 1,  3,  0, 15],\n",
       "        [ 2,  0,  2, 12],\n",
       "        [ 3,  2,  3,  1],\n",
       "        [ 4,  2,  5,  2]])"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 14, 7])"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kt.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "bool value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-180-b6bc013ce49a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mmax_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: bool value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "    x,y=model_max(inputs)\n",
    "    max_result=torch.FloatTensor(len(x),4).zero_()\n",
    "    score=torch.FloatTensor(len(x),2*7,7).zero_()\n",
    "    for q in range(5):\n",
    "        if x[q]>=7:\n",
    "            max_result[q,:]=inputs[q][x[q]-7][y[q]][5:9]\n",
    "        else:\n",
    "            max_result[q,:]=inputs[q][x[q]][y[q]][0:4]\n",
    "        b=0\n",
    "        for i in range(7):\n",
    "            for j in range(7):\n",
    "                squ_label=inputs[q][i][j][0:4]\n",
    "                squ_model=max_result[q,:]\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(checkpoint_path, model, optimizer):\n",
    "    state = {'state_dict': model.state_dict(),\n",
    "             'optimizer' : optimizer.state_dict()}\n",
    "    torch.save(state, checkpoint_path)\n",
    "    print('model saved to %s' % checkpoint_path)\n",
    "    \n",
    "def load_checkpoint(checkpoint_path, model, optimizer):\n",
    "    state = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(state['state_dict'])\n",
    "    optimizer.load_state_dict(state['optimizer'])\n",
    "    print('model loaded from %s' % checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_save(model, epoch, save_interval, log_interval=100):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    criterion=LossFunc()\n",
    "    model.train()\n",
    "    \n",
    "    iteration = 0\n",
    "    for ep in range(epoch):\n",
    "        for batch_idx, (data, target) in enumerate(trainset_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if iteration % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    ep, batch_idx * len(data), len(trainset_loader.dataset),\n",
    "                    100. * batch_idx / len(trainset_loader), loss.item()))\n",
    "            if iteration % save_interval == 0 and iteration > 0:\n",
    "                save_checkpoint('mnist-%i.pth' % iteration, model, optimizer)\n",
    "            iteration += 1\n",
    "    \n",
    "    # save the final model\n",
    "    save_checkpoint('mnist-%i.pth' % iteration, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a brand new model\n",
    "model = Net().to(device)\n",
    "test(model)\n",
    "train_save(model, 5, 500, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
