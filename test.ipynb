{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "import glob\n",
    "import math\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image,resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root = \"/home/yulin/Documents/DLCV/hw2/hw2_train_val/train15000/\"\n",
    "test_root = \"/home/yulin/Documents/DLCV/hw2/hw2_train_val/val1500/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MYDATASET(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        \"\"\" Intialize the MNIST dataset \"\"\"\n",
    "        self.images = None\n",
    "        self.labels = None\n",
    "        self.filenames = []\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        #     parent = os.path.join(path, i)　　read filenames\n",
    "        path = root+\"images/\"\n",
    "        self.filenames=sorted(glob.glob(os.path.join(path,'*.jpg')))\n",
    "        self.len = len(self.filenames)\n",
    "                              \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Get a sample from the dataset \"\"\"\n",
    "        image_fn, label = self.filenames[index]\n",
    "        image = Image.open(image_fn).convert('RGB')\n",
    "        image = Image.resize((448, 448),Image.ANTIALIAS)\n",
    "        path_ = root+'labelTxt_hbb/'\n",
    "        '''txtnames=sorted(glob.glob(os.path_.join(path_,'*.txt'))\n",
    "        img = img.resize((width, height),Image.ANTIALIAS)'''\n",
    "        f = open(path_ +str(index)+'.txt')\n",
    "        line = f.readline()\n",
    "        list = []\n",
    "        while line:\n",
    "            a = line.split( )\n",
    "            b = a[0:]\n",
    "            list.append(b)\n",
    "            line = f.readline()\n",
    "        f.close\n",
    "        label_one=np.zeros((7,7,26))\n",
    "        for s in range(len(list)):\n",
    "            x=0.5*(float(list[s][2])+float(list[s][0]))/512\n",
    "            y=0.5*(float(list[s][5])+float(list[s][1]))/512\n",
    "            w=1*(float(list[s][2])-float(list[s][0]))/512\n",
    "            h=1*(float(list[s][5])-float(list[s][1]))/512\n",
    "            class_=list[s][8]\n",
    "            diff_=list[s][9]\n",
    "            i=math.floor(7*x)\n",
    "            j=math.floor(7*y)\n",
    "            label_one[i][j][0]=x\n",
    "            label_one[i][j][1]=y\n",
    "            label_one[i][j][2]=w\n",
    "            label_one[i][j][3]=h\n",
    "            label_one[i][j][4]=1\n",
    "            if class_==str('plane'):\n",
    "                label_one[i][j][10]=1\n",
    "            if class_==str('ship'):\n",
    "                label_one[i][j][11]=1\n",
    "            if class_==str('storage-tank'):\n",
    "                label_one[i][j][12]=1\n",
    "            if class_==str('baseball-diamond'):\n",
    "                label_one[i][j][13]=1\n",
    "            if class_==str('tennis-court'):\n",
    "                label_one[i][j][14]=1\n",
    "            if class_==str('basketball-court'):\n",
    "                label_one[i][j][15]=1\n",
    "            if class_==str('ground-track-field'):\n",
    "                label_one[i][j][16]=1\n",
    "            if class_==str('harbor'):\n",
    "                label_one[i][j][17]=1\n",
    "            if class_==str('bridge'):\n",
    "                label_one[i][j][18]=1\n",
    "            if class_==str('small-vehicle'):\n",
    "                label_one[i][j][19]=1\n",
    "            if class_==str('large-vehicle'):\n",
    "                label_one[i][j][20]=1\n",
    "            if class_==str('helicopter'):\n",
    "                label_one[i][j][21]=1\n",
    "            if class_==str('roundabout'):\n",
    "                label_one[i][j][22]=1\n",
    "            if class_==str('soccer-ball-field'):\n",
    "                label_one[i][j][23]=1\n",
    "            if class_==str('swimming-pool'):\n",
    "                label_one[i][j][24]=1\n",
    "            if class_==str('container-crane'):\n",
    "                label_one[i][j][25]=1\n",
    "        label = torch.from_numpy(label_one)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" Total number of samples in the dataset \"\"\"\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset=MYDATASET(root=train_root, transform=transforms.ToTensor())\n",
    "testset=MYDATASET(root=test_root, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# images in trainset: 15000\n",
      "# images in testset: 1500\n"
     ]
    }
   ],
   "source": [
    "print('# images in trainset:', len(trainset)) # Should print 15000\n",
    "print('# images in testset:', len(testset)) # Should print 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = Yolov1_vgg16bn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"path=test_lab_path\\ntxtnames=sorted(glob.glob(os.path.join(path,'*.txt')))\\nfor temp in txtnames:\\n    f = open(temp)\\n    line = f.readline()\\n    list = []\\n    while line:\\n        a = line.split( )\\n        b = a[0:]\\n        list.append(b)\\n        line = f.readline()\\n    f.close\\nprint(txtnames)\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"path=test_lab_path\n",
    "txtnames=sorted(glob.glob(os.path.join(path,'*.txt')))\n",
    "for temp in txtnames:\n",
    "    f = open(temp)\n",
    "    line = f.readline()\n",
    "    list = []\n",
    "    while line:\n",
    "        a = line.split( )\n",
    "        b = a[0:]\n",
    "        list.append(b)\n",
    "        line = f.readline()\n",
    "    f.close\n",
    "print(txtnames)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''objectness 分数的计算也使用 sigmoid 函数'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
